{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Node Classification with DeepSNAP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guanchu/DataFormat/blob/master/Node_Classification_with_DeepSNAP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0TzxADD94mG"
      },
      "source": [
        "# **Node Classification with DeepSNAP**\n",
        "\n",
        "This is a tutorial for DeepSNAP node classification.\n",
        "\n",
        "In this tutorial, we will at first introduce the basics of DeepSNAP node classification.\n",
        "\n",
        "Then we will perform node classification by using DeepSNAP on the `Cora` dataset.\n",
        "\n",
        "You might need to **sequentially run all the cells in each section**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hum8zcsDwmGX"
      },
      "source": [
        "# Installation\n",
        "\n",
        "Before running the cells, please go to the `Runtime` and `Change runtime type` to `GPU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OLH-hRMwwlf",
        "outputId": "3ace2742-fd4a-42d6-a9a1-d643be7a5523"
      },
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.5MB 618kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 225kB 28.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 46.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPKqipn-Jwj"
      },
      "source": [
        "# DeepSNAP Node Classification Basics\n",
        "\n",
        "In this section, we will go through the basics of the DeepSNAP node classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuMGKLmXAT2f"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5PAEmxNAXJ1",
        "outputId": "ebb40126-3686-4c45-f0b1-6d8e8f34052e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "source": [
        "import torch\n",
        "import warnings\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from copy import deepcopy\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Disable DeepSNAP warnings for better printout in the tutorial\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f6f024c98590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepsnap/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepsnap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/deepsnap/graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_undirected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m from typing import (\n\u001b[1;32m     11\u001b[0m     \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0min_memory_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from torch_geometric.utils import (contains_isolated_nodes,\n\u001b[1;32m     10\u001b[0m                                    contains_self_loops, is_undirected)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m ]:\n\u001b[1;32m     14\u001b[0m     torch.ops.load_library(importlib.machinery.PathFinder().find_spec(\n\u001b[0;32m---> 15\u001b[0;31m         f'{library}_{suffix}', [osp.dirname(__file__)]).origin)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.7/dist-packages/torch_sparse/_convert_cuda.so: undefined symbol: _ZNK2at6Tensor6deviceEv"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6scu5Cbqwd-Y"
      },
      "source": [
        "## Transductive Node Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdVt2jZS-HrS"
      },
      "source": [
        "We will use the [karate club graph](https://networkx.github.io/documentation/stable/auto_examples/graph/plot_karate_club.html) in the example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKtvZ1mRlmOR"
      },
      "source": [
        "G = nx.karate_club_graph()\n",
        "print(\"The graph has {} nodes and {} edges\".format(G.number_of_nodes(), G.number_of_edges()))\n",
        "pos = nx.spring_layout(G, seed=1)\n",
        "plt.figure(figsize=(8, 8))\n",
        "nx.draw(G, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=\"grey\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvdEym_Jlu8F"
      },
      "source": [
        "def visualize(colors, title=None):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    if title is not None:\n",
        "        plt.title(title, fontsize=20)\n",
        "    nodes = nx.draw_networkx_nodes(H, pos=pos, cmap=plt.get_cmap('coolwarm'), node_color=colors)\n",
        "    nodes.set_edgecolor('black')\n",
        "    edges = nx.draw_networkx_edges(H, pos=pos)\n",
        "    plt.scatter([],[], c='blue', label='Mr. Hi', edgecolors=\"black\", s=140)\n",
        "    plt.scatter([],[], c='red', label='Officer', edgecolors=\"black\", s=140)\n",
        "    if \"grey\" in colors:\n",
        "        plt.scatter([],[], c='grey', label='N/A', edgecolors=\"black\", s=140)\n",
        "    plt.legend(prop={'size': 15}, handletextpad=0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBrkBuoFJEAY"
      },
      "source": [
        "Let's visualize the graph at first!\n",
        "\n",
        "As shown in the plot below, the karate club graph has two communities, which are visualized with two different colors (blue and red)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuF1PkXAEZfs"
      },
      "source": [
        "H = deepcopy(G)\n",
        "node_color = {}\n",
        "community_map = {}\n",
        "for node in H.nodes(data=True):\n",
        "    if node[1][\"club\"] == \"Mr. Hi\":\n",
        "        node_color[node[0]] = \"blue\"\n",
        "        community_map[node[0]] = 0\n",
        "    else:\n",
        "        node_color[node[0]] = \"red\"\n",
        "        community_map[node[0]] = 1\n",
        "nx.classes.function.set_node_attributes(H, community_map, name='node_label')\n",
        "nx.classes.function.set_node_attributes(H, node_color, name='color')\n",
        "colors = nx.get_node_attributes(H, 'color').values()\n",
        "visualize(colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7fB1_L8hUxw"
      },
      "source": [
        "Following is an example for DeepSNAP node classification with dataset creation, dataset split (random) and results visualization on the karate club graph.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSYLoHiaI3-T"
      },
      "source": [
        "# Create the DeepSNAP dataset by setting the task to node (node classification)\n",
        "dg_dataset = GraphDataset([H], task=\"node\")\n",
        "\n",
        "# Random split to train, validation and test sets\n",
        "dataset_train, dataset_val, dataset_test = dg_dataset.split(split_ratio=[0.4, 0.3, 0.3])\n",
        "set_name = [\"Train\", \"Validation\", \"Test\"]\n",
        "for i, dataset in enumerate([dataset_train, dataset_val, dataset_test]):\n",
        "    node_set = set()\n",
        "    colors = []\n",
        "    data = dataset[0]\n",
        "    for node in data.node_label_index:\n",
        "        node_set.add(node.item())\n",
        "    for node in H.nodes():\n",
        "        if node not in node_set:\n",
        "            colors.append(\"grey\")\n",
        "        else:\n",
        "            colors.append(node_color[node])\n",
        "    visualize(colors, title=set_name[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWJT6tSskteW"
      },
      "source": [
        "Plots above show the dataset split results.\n",
        "\n",
        "Blue and red nodes are the nodes splitted to each of the train, validation and test set. Grey nodes mean that the nodes are not available in that set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFLv3sfuYu1X"
      },
      "source": [
        "# Node Classification on Cora Graph\n",
        "\n",
        "Now let's perform transductive node classification task on the `Cora` graph by using the DeepSNAP!\n",
        "\n",
        "In this example, instead of splitting the dataset randomly, we use the `Cora` dataset original fixed node split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17M77hR3ZOFM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi1sCeCJYxwi"
      },
      "source": [
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import networkx as nx\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "from deepsnap.graph import Graph\n",
        "from deepsnap.batch import Batch\n",
        "from deepsnap.dataset import GraphDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xf5j1uTcZby"
      },
      "source": [
        "## A Simple GNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKP42-lMl3NS"
      },
      "source": [
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, args):\n",
        "        super(GNN, self).__init__()\n",
        "        self.num_layers = args[\"num_layers\"]\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(input_size, hidden_size))\n",
        "        for l in range(self.num_layers - 1):\n",
        "            self.convs.append(SAGEConv(hidden_size, hidden_size))\n",
        "        self.post_mp = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.node_feature, data.edge_index, data.batch\n",
        "\n",
        "        for i in range(len(self.convs) - 1):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = F.leaky_relu(x)\n",
        "        x = self.convs[-1](x, edge_index)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.nll_loss(pred, label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVisjZ_ycezD"
      },
      "source": [
        "## Train and Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuIFQDAwm-Jz"
      },
      "source": [
        "def train(train_loader, val_loader, test_loader, args, num_node_features, num_classes,\n",
        "          device=\"cpu\"):\n",
        "    model = GNN(num_node_features, args['hidden_size'], num_classes, args).to(device)\n",
        "    print(model)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=5e-4)\n",
        "\n",
        "    for epoch in range(args['epochs']):\n",
        "        total_loss = 0\n",
        "        model.train()\n",
        "        for batch in train_loader:\n",
        "            batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(batch)\n",
        "            label = batch.node_label\n",
        "            loss = model.loss(pred[batch.node_label_index], label)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        train_acc = test(train_loader, model, device)\n",
        "        val_acc = test(val_loader, model, device)\n",
        "        test_acc = test(test_loader, model, device)\n",
        "        print(\"Epoch {}: Train: {:.4f}, Validation: {:.4f}. Test: {:.4f}, Loss: {:.4f}\".format(\n",
        "            epoch + 1, train_acc, val_acc, test_acc, total_loss))\n",
        "\n",
        "def test(loader, model, device='cuda'):\n",
        "    model.eval()\n",
        "    for batch in loader:\n",
        "        batch.to(device)\n",
        "        logits = model(batch)\n",
        "        pred = logits[batch.node_label_index].max(1)[1]\n",
        "        acc = pred.eq(batch.node_label).sum().item()\n",
        "        total = batch.node_label_index.shape[0]\n",
        "        acc /= total\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6adsL45cjvU"
      },
      "source": [
        "## Start Training!\n",
        "\n",
        "Let's start training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvbev0KKnbNk"
      },
      "source": [
        "args = {\n",
        "    \"device\" : 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    \"hidden_size\" : 128,\n",
        "    \"epochs\" : 100,\n",
        "    \"lr\" : 0.01,\n",
        "    \"num_layers\": 2,\n",
        "    \"dataset\" : \"Cora\",\n",
        "}\n",
        "\n",
        "pyg_dataset = Planetoid('./tmp/cora', args[\"dataset\"])\n",
        "graphs_train, graphs_val, graphs_test = \\\n",
        "    GraphDataset.pyg_to_graphs(pyg_dataset, fixed_split=True)\n",
        "dataset_train, dataset_val, dataset_test = \\\n",
        "    GraphDataset(graphs_train, task='node'), GraphDataset(graphs_val,task='node'), \\\n",
        "    GraphDataset(graphs_test, task='node')\n",
        "\n",
        "train_loader = DataLoader(dataset_train, collate_fn=Batch.collate(), batch_size=1)\n",
        "val_loader = DataLoader(dataset_val, collate_fn=Batch.collate(), batch_size=1)\n",
        "test_loader = DataLoader(dataset_test, collate_fn=Batch.collate(), batch_size=1)\n",
        "num_node_features = dataset_train.num_node_features\n",
        "num_classes = dataset_train.num_node_labels\n",
        "train(train_loader, val_loader,test_loader, args, num_node_features, num_classes, args[\"device\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHXj9082dIIq"
      },
      "source": [
        "More node classification examples please see the [examples/node_classification](https://github.com/snap-stanford/deepsnap/tree/master/examples/node_classification) folder.\n",
        "\n",
        "[Next: Link Prediction with DeepSNAP](https://colab.research.google.com/drive/1ycdlJuse7l2De7wi51lFd_nCuaWgVABc?usp=sharing)"
      ]
    }
  ]
}